{"cells":[{"cell_type":"markdown","id":"d09d1dc6-ef2e-49aa-8dc1-7993d51cbe57","metadata":{"id":"d09d1dc6-ef2e-49aa-8dc1-7993d51cbe57"},"source":["# Pertemuan 14: Advanced Machine Learning using Spark MLlib"]},{"cell_type":"markdown","id":"03b0441f-2c71-42cd-b287-5899d6d75bec","metadata":{"id":"03b0441f-2c71-42cd-b287-5899d6d75bec"},"source":["## Introduction to Spark MLlib\n","Spark MLlib is a scalable library for machine learning that integrates seamlessly with the Spark ecosystem. It supports a wide range of tasks, including regression, classification, clustering, and collaborative filtering."]},{"cell_type":"code","execution_count":null,"id":"2c38d764-75de-4cd7-83ab-e20d9f6b5fb6","metadata":{"id":"2c38d764-75de-4cd7-83ab-e20d9f6b5fb6","outputId":"5a788ce9-9020-46ca-d23c-fe2414ae3a13"},"outputs":[{"name":"stderr","output_type":"stream","text":["25/11/21 09:49:17 WARN Utils: Your hostname, rino-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n","25/11/21 09:49:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","25/11/21 09:49:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","25/11/21 09:49:29 WARN Instrumentation: [880e6534] regParam is zero, which might cause numerical instability and overfitting.\n","25/11/21 09:49:31 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n","25/11/21 09:49:31 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n","25/11/21 09:49:31 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n","25/11/21 09:49:31 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n","                                                                                "]},{"name":"stdout","output_type":"stream","text":["Coefficients: [0.9999999999999992]\n","Intercept: 15.000000000000009\n"]}],"source":["# Example: Linear Regression with Spark MLlib\n","from pyspark.sql import SparkSession\n","from pyspark.ml.regression import LinearRegression\n","from pyspark.ml.feature import VectorAssembler\n","\n","# Initialize Spark Session\n","spark = SparkSession.builder.appName('MLlib Example').getOrCreate()\n","\n","# Load sample data\n","data = [(1, 5.0, 20.0), (2, 10.0, 25.0), (3, 15.0, 30.0), (4, 20.0, 35.0)]\n","columns = ['ID', 'Feature', 'Target']\n","df = spark.createDataFrame(data, columns)\n","\n","# Prepare data for modeling\n","assembler = VectorAssembler(inputCols=['Feature'], outputCol='Features')\n","df_transformed = assembler.transform(df)\n","\n","# Train a linear regression model\n","lr = LinearRegression(featuresCol='Features', labelCol='Target')\n","model = lr.fit(df_transformed)\n","\n","# Print model coefficients\n","print(f'Coefficients: {model.coefficients}')\n","print(f'Intercept: {model.intercept}')\n"]},{"cell_type":"code","execution_count":null,"id":"4c45863a-d1f8-4945-92ba-d969f333a0ba","metadata":{"id":"4c45863a-d1f8-4945-92ba-d969f333a0ba","outputId":"66879e98-32ee-485c-e4bd-1b64d03bffc6"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                "]},{"name":"stdout","output_type":"stream","text":["Coefficients: [-12.262057928656196,4.087352266314726]\n","Intercept: 11.568912726114789\n"]}],"source":["from pyspark.ml.classification import LogisticRegression\n","from pyspark.ml.feature import VectorAssembler\n","\n","# Example dataset\n","data = [(1, 2.0, 3.0, 0),\n","        (2, 1.0, 5.0, 1),\n","        (3, 2.5, 4.5, 1),\n","        (4, 3.0, 6.0, 0)]\n","\n","columns = ['ID', 'F1', 'F2', 'Label']\n","df = spark.createDataFrame(data, columns)\n","\n","# Convert features into a vector\n","assembler = VectorAssembler(inputCols=['F1', 'F2'], outputCol='Features')\n","df_vector = assembler.transform(df)\n","\n","# Train logistic regression model\n","lr = LogisticRegression(featuresCol='Features', labelCol='Label')\n","model = lr.fit(df_vector)\n","\n","# Display coefficients and summary\n","print(f'Coefficients: {model.coefficients}')\n","print(f'Intercept: {model.intercept}')\n","\n"]},{"cell_type":"code","execution_count":null,"id":"81db34a8-ac47-4c67-b017-56c2ccdb1ea5","metadata":{"id":"81db34a8-ac47-4c67-b017-56c2ccdb1ea5","outputId":"34ae35f5-c8ac-4c5a-9cc3-1f6d062a323e"},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 48:>                                                         (0 + 4) / 4]"]},{"name":"stdout","output_type":"stream","text":["Cluster Centers: [array([12.5, 12.5]), array([3., 3.])]\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                "]}],"source":["from pyspark.ml.clustering import KMeans\n","from pyspark.ml.feature import VectorAssembler\n","\n","# Example dataset\n","data = [(1, 1.0, 1.0),\n","        (2, 5.0, 5.0),\n","        (3, 10.0, 10.0),\n","        (4, 15.0, 15.0)]\n","\n","columns = ['ID', 'F1', 'F2']\n","df = spark.createDataFrame(data, columns)\n","\n","# Convert to vector\n","assembler = VectorAssembler(inputCols=['F1', 'F2'], outputCol='Features')\n","df_vector = assembler.transform(df)\n","\n","# Train KMeans clustering model\n","kmeans = KMeans(featuresCol='Features', k=2)\n","model = kmeans.fit(df_vector)\n","\n","# Show cluster centers\n","centers = model.clusterCenters()\n","print(f'Cluster Centers: {centers}')\n"]},{"cell_type":"markdown","id":"8e19d85d-dfec-4cd3-93be-87d1914f6681","metadata":{"id":"8e19d85d-dfec-4cd3-93be-87d1914f6681"},"source":["## Homework\n","- Load a real-world dataset into Spark and prepare it for machine learning tasks.\n","- Build a classification model using Spark MLlib and evaluate its performance.\n","- Explore hyperparameter tuning using cross-validation."]},{"cell_type":"code","execution_count":null,"id":"64c06243-55ed-44d8-af13-892e5efc849d","metadata":{"id":"64c06243-55ed-44d8-af13-892e5efc849d","outputId":"0b4fd7b8-69e9-4e17-a11b-9579946afbcd"},"outputs":[{"name":"stderr","output_type":"stream","text":["25/11/21 10:38:23 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"]},{"name":"stdout","output_type":"stream","text":["root\n"," |-- PassengerId: integer (nullable = true)\n"," |-- Survived: integer (nullable = true)\n"," |-- Pclass: integer (nullable = true)\n"," |-- Name: string (nullable = true)\n"," |-- Sex: string (nullable = true)\n"," |-- Age: double (nullable = true)\n"," |-- SibSp: integer (nullable = true)\n"," |-- Parch: integer (nullable = true)\n"," |-- Ticket: string (nullable = true)\n"," |-- Fare: double (nullable = true)\n"," |-- Cabin: string (nullable = true)\n"," |-- Embarked: string (nullable = true)\n","\n","AUC Score: 0.8650468384074942\n","+--------+----------+----------------------------------------+\n","|Survived|prediction|probability                             |\n","+--------+----------+----------------------------------------+\n","|0       |1.0       |[0.11673391185638055,0.8832660881436194]|\n","|0       |1.0       |[0.48190279316756396,0.5180972068324361]|\n","|0       |1.0       |[0.3737633511389316,0.6262366488610684] |\n","|0       |0.0       |[0.5433539344723657,0.4566460655276343] |\n","|0       |0.0       |[0.5486642317163983,0.45133576828360167]|\n","|0       |0.0       |[0.5485045079086552,0.45149549209134476]|\n","|0       |0.0       |[0.5416478980328538,0.45835210196714615]|\n","|0       |1.0       |[0.46224361190659113,0.5377563880934089]|\n","|0       |0.0       |[0.5280323410449957,0.47196765895500425]|\n","|0       |0.0       |[0.6577289922371665,0.3422710077628335] |\n","+--------+----------+----------------------------------------+\n","only showing top 10 rows\n","\n"]}],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, when\n","from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n","from pyspark.ml.classification import LogisticRegression\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n","\n","#1. Start Spark Session\n","spark = SparkSession.builder.appName(\"Titanic-MLlib\").getOrCreate()\n","\n","# 2. Load Dataset\n","df = spark.read.csv(\"train.csv\", header=True, inferSchema=True)\n","df.printSchema()\n","\n","# 3. Select dan Bersihkan Data\n","df = df.select(\n","    \"Survived\", \"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\"\n",")\n","\n","# Isi missing values\n","df = df.fillna({\n","    \"Age\": df.agg({\"Age\": \"mean\"}).first()[0],\n","    \"Embarked\": \"S\"\n","})\n","\n","# 4. Feature Engineering\n","# Encoding kolom kategori\n","sex_indexer = StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndex\")\n","emb_indexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"EmbarkedIndex\")\n","\n","encoder = OneHotEncoder(\n","    inputCols=[\"SexIndex\", \"EmbarkedIndex\"],\n","    outputCols=[\"SexVec\", \"EmbarkedVec\"]\n",")\n","\n","# 5. Vector Assembler (Gabungkan fitur)\n","assembler = VectorAssembler(\n","    inputCols=[\"Pclass\", \"Age\", \"Fare\", \"SexVec\", \"EmbarkedVec\"],\n","    outputCol=\"features\"\n",")\n","\n","# 6. Model\n","lr = LogisticRegression(labelCol=\"Survived\", featuresCol=\"features\")\n","\n","# 7. Pipeline\n","from pyspark.ml import Pipeline\n","\n","pipeline = Pipeline(stages=[sex_indexer, emb_indexer, encoder, assembler, lr])\n","\n","# 8. Train-test split\n","train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n","\n","# 9. Hyperparameter Tuning\n","paramGrid = (ParamGridBuilder()\n","             .addGrid(lr.regParam, [0.01, 0.1, 0.5])\n","             .addGrid(lr.maxIter, [10, 20, 50])\n","             .build())\n","\n","evaluator = BinaryClassificationEvaluator(\n","    labelCol=\"Survived\",\n","    rawPredictionCol=\"rawPrediction\",\n","    metricName=\"areaUnderROC\"\n",")\n","\n","cv = CrossValidator(\n","    estimator=pipeline,\n","    estimatorParamMaps=paramGrid,\n","    evaluator=evaluator,\n","    numFolds=3\n",")\n","\n","# 10. Training Final Model\n","cv_model = cv.fit(train_data)\n","\n","# 11. Evaluation\n","predictions = cv_model.transform(test_data)\n","\n","auc = evaluator.evaluate(predictions)\n","print(\"AUC Score:\", auc)\n","\n","predictions.select(\"Survived\", \"prediction\", \"probability\").show(10, truncate=False)\n"]},{"cell_type":"code","execution_count":null,"id":"4a67a0f5-77fe-4d62-8a9e-483dc72b2fd0","metadata":{"id":"4a67a0f5-77fe-4d62-8a9e-483dc72b2fd0"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python (rinobigdata)","language":"python","name":"rinobigdata"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.14"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}